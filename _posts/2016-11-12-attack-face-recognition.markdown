---
layout: post
title:  "一种危险的攻击人脸识别系统的方法"
date:   2016-11-12 Sat 14:05:06
categories: FaceRecognition
---

**原文**：[Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition](http://dl.acm.org/citation.cfm?doid=2976749.2978392)。

第一作者 [Mahmood Sharif](https://users.ece.cmu.edu/~mahmoods/) 是 CMU 的一名博士研究生；主要作者都是 CMU 的研究人员。

---
<br/>

#### 这篇文章是要实现一种瞒过人脸识别技术的方法，并且要满足下述两个条件

- 不引人注意 (inconspicuousness)：反面例子是，可以通过化很夸张的妆来瞒过人脸识别系统，但这样会很容易被旁边的人 (比如保安) 看出来。
- 物理上可实现：也就是说，需要的设备是可以制作出来的。

#### 作者把对人脸识别系统的攻击分成了两类

- 伪装他人 (impersonation)：目的是让人脸识别系统把正在识别的人识别为另一个特定的人。这对身份验证系统是个很危险的事情。
- 逃避识别 (dodging)：目的是让人脸识别系统把正在识别的人识别为别的任何一个人。这个可用于逃避视频监控。

#### 本文实现的方法

- 一种可以自行打印的彩色纸质眼镜框
    - 给出了白盒攻击 (知道算法细节) 和黑盒攻击 (不知道算法细节) 的方法
    - 给出了如何让这眼镜框上的图案不引人注意的方法
- 针对前沿的人脸识别技术，在逃避识别任务上达到 80% 的成功率
- 在伪装他人方面，可以让一个白人男性伪装成 [Milla Jovovich](https://cn.bing.com/images/search?q=Milla+Jovovich&FORM=HDRSC2) (生化危机系列的主演)，达到 87.87% 的成功率
- 给出了在人脸识别系统前面“隐身”的方法

#### 相关的工作

- 类似的工作有通过化妆和发型来逃避人脸识别系统的，还有借助红外发射器干扰摄像头感光器件的
- 还有借助 3D 打印的面具的
- 逆向攻击技术：从人脸识别系统背后的神经网络重构人脸
- Szegedy 等人曾发现可以通过对输入数据加入轻微干扰来误导深度神经网络

#### 技术细节

- 伪装他人：最小化把 A 识别为 B 的误差
- 逃避识别：最小化把 A 识别为 A 的几率
- 只对面部眼镜框所在位置的像素调颜色
    - 眼镜框所占面积不超过 6.5%
    - 通过微移眼镜框的位置来提高健壮性
    - 要求眼镜框的颜色分布对一系列图形都有效
    - 要求眼镜框的颜色分布足够平滑
    - 要求眼镜框的颜色适合打印机打印
- 计算时间大约 4 个小时 (MacBook Pro)

#### 效果

<img src="{{ site.url }}/pictures/2016-11-12-attack-face-recognition-1.png" id="Fig1">
<p class="image-caption">通过带上一个眼镜框来伪装他人。第一行的图是伪装者，第二行的图是人脸识别系统识别出的结果。</p>

#### 黑盒攻击

- [Face++](http://www.faceplusplus.com/)
    - 每个用户每月 50000 次免费请求
- 粒子集群优化算法
- 只需要几十次到一百次请求即可攻击成功

#### 隐形 (让人脸探测器检测不到人脸)

- Viola-Jones 人脸探测
    - 一系列弱探测器的级联组合
- 只要能逃避一层探测器就足够

#### 后果

- 蛮严重的

#### 可能的防范措施

- 作者没有详细说
- 只是说希望开发出更接近人类处理图像的方式的算法
    - 基于属性，而不是基于像素的亮度
    - 上面这句话啥意思我也不明白

#### 本文方法的局限性

- 现实场景光照条件更复杂
- 与摄像头的距离也有影响
- “不引人注意”的限制带有主观性
