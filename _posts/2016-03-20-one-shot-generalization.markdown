---
layout: post
title:  "深度生成模型的单次泛化"
date:   2016-03-20 Sun 00:50:49
categories: artificial intelligence
---

本文为翻译文章，仅供个人学习之用。

本文作者特别喜欢用 compelling 这个词，简直受不了，并且不确定对应的中文是什么。

<h3>原文网址</h3>
[arxiv](http://arxiv.org/abs/1603.05106)


<h1>摘要</h1>

人类善于仅凭单个例子对新概念和经验进行推理。特别是，人类有单次泛化的能力：遭遇新概念，理解其结构，然后生成概念的有意义的变型。我们基于深度生成模型发展了一套有这种重要能力的机器学习系统；这种模型结合了深度学习的表达能力和贝叶斯推断的推测能力。我们开发了一类基于反馈和注意的序列生成模型。这两个特征让生成模型在密度估计和图像生成方面都达到了领域前沿。我们用三个任务来展示我们模型的单点泛化能力：无条件采样，生成给定概念的新实例，以及生成一系列概念的实例。在所有情形我们的模型都可以在仅仅看一次实例的情况下生成有意义且多样的样本，因此我们的模型提供了一类重要的单次机器学习的一般性模型。

<h1>引言</h1>

<p>考虑图 1 中红框里的部分。我们只需要看里面每个新概念一次，理解它们的结构，然后就能想象并生成每个概念的变型，就像红框下面的那些符号一样。这是人类拥有的单词泛化能力：从一个或少数几个例子推广到新概念的能力。本文中我们开发新的拥有这种能力的模型——可以从实际中可能遇到的数据流做出单次推理，仅使用有限形式的领域知识，并能应用到不同种类的问题。</p>

<p>
有几种单点泛化的方法。Salakhutdinov et al. (2013) 发展了一个结合了玻耳兹曼机和等级狄利克雷过程的概率模型，可以学习层级概念类别，并且提供了强大的生成模型。最近，Lake et al. (2015) 等人把贝叶斯规划学习所具有的单次泛化能力视为“神经网络模型的一个挑战”。通过把深度神经网络嵌入到层级隐变量模型里并与近似贝叶斯推断的推测能力结合，这个挑战是可以克服的。得到的深度生成模型是一般性的图像模型，准确且可伸缩，前沿，具有重要的泛化能力。
</p>
