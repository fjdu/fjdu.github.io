---
layout: post
title:  "强人工智能的出现似乎不可避免"
date:   2016-03-11 Fri 02:38:19
categories: artificial intelligence
---

程序语言领域有个名言叫做“格林斯潘第十诫” (Greenspun's tenth rule)，说的是，任何足够复杂的 C 或 Fortran 程序都包含一个临时拼凑的、没有正式定义的、充满 bug 的、并且速度慢的 Common Lisp 的一半实现。并且还有个推论：用 Common Lisp 写的程序也不例外。

按照维基百科，这个“定律”本身有两种解读方式：第一种是，由于 Lisp 语言的灵活性和可扩展性，它已经包含了任何为了设计一个复杂系统理论上需要的全部功能，而用别的语言开发出的这些功能等价于 Lisp 里的相应方法。第二种是在讽刺那些复杂而高度可定制化的系统。与其自己设计一套这种系统，格林斯潘建议用一个广泛接收的、特性完备的语言，比如 Lisp。

这里要说的不是程序语言，而是人工智能，或者说，是“通过部分地模仿人类头脑为人类服务的软硬件设备”，所以我提供第三种解读：当一个系统足够复杂、功能足够强大，则必然会引入一些“自省”系统。所谓“自省”，也就是自我反省，比如问“我为什么存在”这种问题就是一种自省。为什么呢？因为要功能强大，这个系统必须回答“自己如何更好地存在”这样的问题，也就是利用搜集的各种信息发现自身局限性并且提高自身的能力，以及“如何更好地发现自身的局限性并提高自身的能力”。当一个系统具有较高水准的这种能力后，就算是拥有智能了。

我觉得吧，如今说强人工智能不可能实现的，可能就跟不久前说电脑不可能在围棋项目上战胜人类的人一样。只要认可人是一台机器 --- 虽然是极端复杂的机器 --- 有什么理由认为同样作为机器的电脑不可能“模拟”人脑的功能呢？

