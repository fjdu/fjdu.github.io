---
layout: post
title:  "通往机器智能之路线图"
date:   2016-04-18 Mon 20:46:11
categories: artificial intelligence
---

作者：Tomas Mikolov, Armand Joulin, and Marco Baroni

摘自 Tomas Mikolov 的一个[口头报告](https://www.youtube.com/watch?v=FUlTjKL-mVA)。

原文链接：[arXiv](http://arxiv.org/abs/1511.08130)，一共 36 页

<hr>
<p></p>

# 基于交流的 AI 的终极目标

几乎可以做任何事：

- 帮助学生理解作业
- 帮助研究人员找到相关信息
- 写程序
- 帮助科学家解决需要几百年才能完成的任务

# 路线图

- 我们描述了智能机器必须包含的最少组件
- 构建方法
- 可规模化的要求

# 智能机器的组件

- 能够交流
- 动机组件
- 学习技能 (需要长期记忆)，能够改变自身以适应新问题

# 架构组件

- 让机器学习基本的交流和学习技能的环境
- 交流通道
- 奖励
- 渐增结构

# 模拟环境

- 没有已知的能够教机器学习交流技能的数据集
- 仔细设计任务，比如复杂性的增长速度
    - 如果复杂性增长太快，设计再好的智能机器也可能失败
    - 复杂性增长太慢，则达不到最终目的

# 环境的高层次描述

- 模拟环境
    - 学习者
    - 教师
    - 奖励

- 规模化
    - 更多复杂问题，更少的任务，更少的监督
    - 与真人交流
    - 真实输入信号 (比如互联网)

# 模拟环境：代理人

- 环境：简单的基于脚本的反应式代理，为学习者产生信号，代表世界
- 学习者：接受输入信号和奖励信号的智能机器，产生输出信号让奖励最大化
- 教师：为学习者提供任务，起初基于脚本，之后由人类用户代替

# 模拟环境：交流

- 学习者的输入通道：教师和环境通过这个通道写入
- 学习者的输出通道：影响它在环境中的行为，可用来与教师沟通
- 奖励也是 IO 通道的一部分

# 通过可视化达到更好的理解

- 输入/输出流的可视化
- 命令输入，接收确认
- 命令执行，结果确认
- 奖励最大化
- 为了可规模化，系统设计必须从一开始就尽量采用无监督途径

# 如何规模化：快速学习

- 我们可以很容易地通过大量尝试在模拟世界制造出能“解决”简单问题的机器，但对复杂问题这种策略不可行
- 一般来说，给学习者新类型的行为并指导它尝试几个新任务就足以让它今后在类似任务中胜任
- 通过奖励机制，对监督的需要会越来越少

# 如何规模化：让人类参加进来

- 快速学习的学习者可以跟人类专家学习，学到新颖行为
- 之后，拥有基本交流能力的预先训练的学习者可以被人类中不是专家的那部分使用

# 如何规模化：让真实世界加入

- 学习者可以通过 IO 通道连接互联网
- 让学习者学会通过输出流提交互联网请求

# 对新技术的需求

<p>现有技术难以学习某些对人来说平凡的模式 (比如 \(a^n b^n\) 这样简单的算法模式)：</p>

- 上下文无关语法超出了当前复现神经网络 (RNN) 的能力
- 序列记忆不管用
- [Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets](http://arxiv.org/abs/1503.01007): 通过对 RNN 作出简单改进，可以获得做简单计算的能力，有点意思

# 规模化

想要机器能被用于更复杂的问题，我们需要

- 长期记忆
- (图灵) 完备且高效的计算模型
- 渐增式、组合式学习；先学简单技能，在此基础上提高
- 基于少量例子快速学习
- 通过奖励机制减少监督 (人类也是这样)

# 向前迈进：Stack RNN, 栈式复现神经网络 ([Joulin & Mikolov 2015](http://arxiv.org/abs/1503.01007))

- 简单的 RNN 加上长期记忆扩展；神经网络学会控制记忆
- 很老的想法了 (八九十年代); 过去采用了拓扑记忆；本文采用最简单的，栈结构
- 目前的版本很简单，但已经可以学到远超过去达到的复杂度的模式了 (尽管仍然像个玩具)：监督少了许多，而可以规模化到更复杂的任务

# 栈式 RNN

- 一个或多个栈
- 从例子中学习算法
- 跟 RNN 仍然很像；在 RNN 的复现矩阵中添加了特别的连接；有了结构化存储
    - 可训练的读写
    - 没有界限
- 隐层决定作出什么行为
- 操作：PUSH, POP, NO-OP
- 整个系统架构仍然是可微的，用随机梯度下降训练
- 存储结构的例子：栈，链表，队列，磁带，格点

# 算法模式

<p>
<ul>
<li> \(\{a^nb^n | n>0\}\)</li>
<li> \(\{a^nb^nc^n | n>0\}\)</li>
<li> \(\{a^nb^nc^nd^n | n>0\}\)</li>
<li> \(\{a^nb^{2n} | n>0\}\)</li>
<li> \(\{a^nb^mc^{n+m} | n,m>0\}\)</li>
<li> \(n \in [1,k], X\rightarrow nXn, X\rightarrow=\)</li>
<li> 这些也可以用 LSTM 解决；任何包含线性层，可以执行加一减一操作的都可以</li>
<li> 目标是通过观察例子无监督学到这些模式</li>
</ul>
</p>

# 算法模式：计数

- 使用 sigmoidal 激活函数的 RNN 不会数数，只会死记硬背
- 栈式 RNN 和 LSTM 会数数
- 栈式 RNN 40 ＋ 10 ＋ rounding 的表现最佳，在上面几个任务中达到 100% 准确率

# 算法模式：序列

- 序列记忆和二进制加法超出了 LSTM 的能力范围
- 可扩展的栈存储让学到解决方案成为可能

# 二进制加法

- 无监督训练；仅仅是预言
- 学会了：存储数字，何时输出，何时进位

# 栈式 RNN：总结

优点：

- 图灵完备 (>=2 个栈)
- 能学习算法模式
- 有长期记忆
- 能解决某些 RNN 和 LSTM 不能解决的问题
- 结果可重现，代码公开: [Github](https://github.com/facebook/Stack-RNN)

缺点：

- 长期记忆只用来存储部分计算结果 (而不是用来存储学到的技能)
- 不像是渐增学习的好模型，因为计算效率低
- 关于存储的拓扑结构，栈不像是有一般性意义的 (现代计算机是图灵完备的，但不是图灵机，因为如果真的用图灵机的结构的话，效率太低了)

# 结论

要实现真正的人工智能，我们需要：

- 以AI-完备为目标；要有野心，而不止是下棋机器这样的
- 新型任务
- 发展新技术；RNN 很厉害，但没法完成某些简单任务
- 激励更多人来解决这些问题

# 问答

- 梯度消失问题
    - 自连接缓解了这个问题
- 人类没有接受很多监督就具有高级智能; 自我激励？
    - 弱监督学习，奖励机制
- GRU 网络？
    - 为了简化 LSTM 的结构；门机制，长期记忆；同一个月发表
- 基于生物学的模型是否必要
    - 难以回答；做出来才知道；没必要精确复制；飞机不需要扇翅膀；某些神经学家用机器学习的成果去解释神经学现象
- 简单练习项目？
    - 自己生成一些模式让机器来学习，因为缺数据
    - Imagenet: 不是 AI-完备
    - 玩游戏：也不是，只要计算能力够强就行，没有什么新技术
    - 可能会发布这种简单环境
- 如何聪明地避免梯度爆炸
    - 作为超参数，凭经验，与具体值有关，可能可以设置一些阈值，但效果不会很大
- 二阶 RNN 学习方法是否有效
    - 他个人认为不那么有效, 参见他的网站
- 如何调超参数
    - 超参数越少越好，训练数据越多越好
    - 基于流程设置学习率，不需要调节
    - 隐含层越多越好，受限于计算资源
    - 也许可以通过算法自动决定这些超参数
- 会写书、能理解自然规律、会调情的人工智能在当前机器学习范式下是否有可能实现
    - 他们的文章就是讲这个的
    - 真正的智能不应该把数据分成训练数据、保留数据、检验数据几个部分；应该一边读入数据一边训练
    - 并行很必要

<hr>
<p></p>

<section>
<img src="{{ site.url }}/pictures/2016-04-18-mikolov.png" id="Fig1">
<p class="image-caption"><a href="https://research.facebook.com/tomas-mikolov">Tomas Mikolov</a></p></img>
</section>
