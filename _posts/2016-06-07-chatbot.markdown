---
layout: post
title:  "聊天机器人概述"
date:   2016-06-07 Tue 15:57:33
categories: machine learning
---

来源：[Deep learning for chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)

<hr><p></p>

# 业界

大玩家：微软，Facebook，Apple Siri，Google，微信，Slack

初创：[Operator](https://operator.com/)，[x.ai](https://x.ai/)，[Chatfuel](http://chatfuel.com/)

开发框架：[Howdy’s Botkit](https://howdy.ai/botkit/), [bot developer framework](https://dev.botframework.com/)

<hr><p></p>

# 分类

基于信息检索的模型与生成模型

  - 基于信息检索 (容易): 规则明确，回复内容限制在事先确定的范围内；只要准备得好，不会有语法错误
  - 基于生成模型 (较难): 把问题“翻译成”回答；需要大量数据来训练；回答可能包含语法错误
  - 目前多数可用的系统是第一类


长对话与短对话

  - 短对话只需要针对特定问题给出恰当回答
  - 而长对话需要多重转折并保持历史记录
  - 客服对话一般属于长对话

开放式对话与封闭式对话

  - 社交媒体上的讨论一般是开放式对话，对话可以从一个点发散到任何话题
  - 客户技术支持或者购物助理一般属于封闭式对话；超出范畴的对话即便出错也可以容忍

<hr><p></p>

# 挑战

语言场景与物理场景的引入

  - 词语嵌入
  - 端到端等级生成模型
  - [意图导向型专注模型](http://arxiv.org/abs/1510.08565)

一致的人格特征

  - 对不同问题给出的答案应该对应一致的人格实体
  - 比如对“你多大”与“你几岁”的回答应该相同，对“你住哪儿”与“你所在的城市是哪个”的回答不应该有矛盾
  - [基于人格的神经对话模型](http://arxiv.org/abs/1603.06155)

模型的评估

  - 常常需要人工评定
  - 有时候没有良好定义的目标
  - 用于评定机器翻译的 BLEU 评分不适合用来评价聊天机器人
  - 常用的自动评价系统与人工判定的结果[不一致](http://arxiv.org/abs/1603.08023)

意图与多样性

  - 没有人喜欢敷衍的回答 (早期 Google 的智能回复倾向于对任何问题都回答“爱你”；由训练数据和训练目标导致)
  - 故意通过改变目标函数来促进多样性也不好，因为人类回答问题一般是带有意图的
  - 开放式对话系统的生成模型的训练目标不涉及意图，所以缺乏这种能力

<hr><p></p>

# 实际表现

  - 开放系统的生成模型几乎相当于通用人工智能了; 离这个目标还差得远
  - 基于生成模型或信息检索的封闭系统
    - 众包生成初始训练数据；仅适用于非常狭窄的领域
    - 为人工服务提供辅助，这是可行的
  - 语法错误代价高昂
    - 可能会赶走用户
    - 通过信息检索模型避免语法错误和冒犯性言语
    - 生成模型给出的回答必须由其它技术辅助一面出轨 (微软 Tay 的错误)

<hr><p></p>

